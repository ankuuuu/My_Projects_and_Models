{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Model With Tfidf Vectorization !\n",
    "\n",
    "    We create a NLP model and predict out the probabality of our model is good aur bad !\n",
    "\n",
    "    We are going to perform *vectorization technique !\n",
    "\n",
    "    Also doing multihotcoding !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data from csv file !\n",
    "\n",
    "dataset = pd.read_csv('balanced_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's do some investigation !\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['overall', 'reviewText', 'summary']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261644    DO NOT ORDER. Yeah the picture is super cute. ...\n",
       "650690    They fit as expected because I read all the re...\n",
       "350368    Needed for a special event.  The price was goo...\n",
       "4424                                                  Great\n",
       "628025    These shoes are cute and comfortable, but had ...\n",
       "85001     This is a cute purse. I love the sizing but th...\n",
       "11041     I loved this watch . . . at first. In February...\n",
       "701069    Really cute.  Mine was not so polished when I ...\n",
       "460133    Basically a very good product except some will...\n",
       "89558     This ring looks nice, but I ordered a size 10 ...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the 10 reviewtext randomly !\n",
    "\n",
    "dataset['reviewText'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Great nephew loved!!! Very fast delivery!!!!!\n",
       "1                       well made boot, fits perfectly\n",
       "2    Perfect fit. Good quality. (Do not put in dryer.)\n",
       "3    I bought these for my 2 year old girl and she ...\n",
       "4    Great backpack.  I wanted to get a backpack th...\n",
       "5    I use these every day.  They smell great and w...\n",
       "6                                           Nice pants\n",
       "7    The first pair of jazz shoes my daughter didn'...\n",
       "8    Got these shoes for my elderly mother. They fi...\n",
       "9    I love the Keen Newport Sandal!, they are dura...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 reviewtext!\n",
    "\n",
    "dataset['reviewText'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In overall we have ratings let's know the counts for ratings 1-5 !\n",
    "\n",
    "dataset['overall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    264000\n",
       "5    132000\n",
       "4    132000\n",
       "2    132000\n",
       "1    132000\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's count how many reviews we have for 1 - 5 !\n",
    "\n",
    "dataset['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall       False\n",
       "reviewText     True\n",
       "summary        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values !\n",
    "\n",
    "dataset.isnull().any(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the columns where we have missing data !\n",
    "\n",
    "dataset.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall       False\n",
       "reviewText    False\n",
       "summary       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again check the missing values !\n",
    "\n",
    "dataset.isnull().any(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the data which have ratings - 3 !\n",
    "\n",
    "dataset = dataset[dataset['overall'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    131939\n",
       "1    131876\n",
       "4    131849\n",
       "5    131719\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check is there rating3 droped aur not !?\n",
    "dataset['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new columns !\n",
    "\n",
    "    And divided the overall ratings in two categories !\n",
    "    0 - negative ratings !\n",
    "    1 - positive ratings !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Positivity'] = np.where(dataset['overall'] > 3 , 1 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    263815\n",
       "1    263568\n",
       "Name: Positivity, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check ratings and there count Positivity Column !\n",
    "\n",
    "dataset['Positivity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Great nephew loved!!! Very fast delivery!!!!!\n",
       "1                       well made boot, fits perfectly\n",
       "2    Perfect fit. Good quality. (Do not put in dryer.)\n",
       "3    I bought these for my 2 year old girl and she ...\n",
       "4    Great backpack.  I wanted to get a backpack th...\n",
       "5    I use these every day.  They smell great and w...\n",
       "6                                           Nice pants\n",
       "7    The first pair of jazz shoes my daughter didn'...\n",
       "8    Got these shoes for my elderly mother. They fi...\n",
       "9    I love the Keen Newport Sandal!, they are dura...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['reviewText'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Data we have to convert our freeform text data into numeric representation !\n",
    "\n",
    "    To create a ML model all algorithms need data in numeric format. !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the features and labels !\n",
    "\n",
    "features = dataset['reviewText']\n",
    "\n",
    "labels = dataset['Positivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test !\n",
    "\n",
    "features_train , features_test , labels_train , labels_test = train_test_split(features , labels , test_size = 0.4 ,\n",
    "                                                                               random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert our NLP text data to a numeric representation using *Vectorization technique !\n",
    "\n",
    "    We are going to use TfidfVectorizer !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a class !\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a object !\n",
    "\n",
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the daqta !\n",
    "\n",
    "vect = TfidfVectorizer(min_df = 5).fit(features_train) \n",
    "\n",
    "# min_df = 5 means ignore the terms that appear in less then 5 documents !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17313"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the count of unique words !\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NLP test data in numeric representation !\n",
    "\n",
    "features_train_vectorized = vect.transform(features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can covert our features_train_vectorized to array using .toarray() function !\n",
    "\n",
    "    But sometime in this process our system get crashed !\n",
    "\n",
    "    features_train_vectorised.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LogisticRegression Model !\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object of it !\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bad Boy\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now fitt our data !\n",
    "\n",
    "model.fit(features_train_vectorized , labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Models !\n",
    "# Model Testing !\n",
    "\n",
    "prediction = model.predict(vect.transform(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our Model is Working Good aur Bad interms of Classification !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Confusion Matrix !\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95985,  9307],\n",
       "       [11418, 94244]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_test , prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the Probability of our Model !¶\n",
    "\n",
    "    Probability < 50 = 0 !\n",
    "    Probability >= 50 = 1 !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Calculate rthe Accuracy of the Model !\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017558330252093"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_test , prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03106634, 0.96893366],\n",
       "       [0.52192257, 0.47807743],\n",
       "       [0.98897343, 0.01102657],\n",
       "       ...,\n",
       "       [0.00485688, 0.99514312],\n",
       "       [0.11682304, 0.88317696],\n",
       "       [0.38697599, 0.61302401]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(vect.transform(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction the Probability / Score of our model is - 90.12% !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
